{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(s_date, e_date):\n",
    "    root_path = \"\"\n",
    "    base_name = \"station_data_\"\n",
    "    extender = \".csv\"\n",
    "    s_date = str(s_date)\n",
    "    e_date = str(e_date)\n",
    "    s_date = s_date[2:4]+s_date[5:7]+s_date[8:10]\n",
    "    e_date = e_date[2:4]+e_date[5:7]+e_date[8:10]\n",
    "\n",
    "    file_name = root_path+base_name+s_date+\"_\"+e_date+extender\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1 정류장 파일 읽어온 뒤, 'city(시)' 필드 추가\n",
    "#### 1-2 제주시, 서귀포시 정류장 dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2019, 6, 1)\n",
    "end_date = datetime.datetime(2019, 8, 29)\n",
    "file_path = make_path(start_date, end_date)\n",
    "df = pd.read_csv(file_path, encoding=\"CP949\")\n",
    "\n",
    "df['cluster_group'] = df['station_address'].apply(lambda string: string.split(' ')[1])\n",
    "                    # (예) 'STATION_ADDR': 서귀포시 중문동 ... ☞ 'city': 서귀포시\n",
    "group_label_list = list(df[\"cluster_group\"].value_counts().index)\n",
    "    \n",
    "grouped_df_list = []\n",
    "for label in group_label_list:\n",
    "    grouped_df_list.append(df[df[\"cluster_group\"] == label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_s = 'cluster_target'\n",
    "level_s = 'cluster_level'\n",
    "earth_radius = 6371.0088 # 단위: km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_level_spatial_dbscan_result \\\n",
    "    (df, n, eps, min_pts = 3, nonf_cols = ['station_id', 'station_name'], f_cols = ['station_x', 'station_y']):\n",
    "    global earth_radius \n",
    "    dbscan = DBSCAN(eps = eps/1000/earth_radius, algorithm='ball_tree', \n",
    "                    metric='haversine', min_samples=min_pts)\n",
    "    \n",
    "    temp_df = df.loc[:, nonf_cols + f_cols]\n",
    "    temp_df.loc[:, target_s] = dbscan.fit_predict(np.radians(temp_df[f_cols]))\n",
    "\n",
    "    success_index = temp_df.query(target_s + ' > -1').index\n",
    "    temp_df.loc[success_index, level_s] = str(n)\n",
    "    \n",
    "    failed_index = set(temp_df.index) - set(success_index)\n",
    "    temp_df.loc[failed_index, level_s] = str(-1)\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_handled_result \\\n",
    "    (df, n, by1='station_id', by2='station_name', f_cols=['station_x', 'station_y']):\n",
    "    temp_df = df.loc[:, [by1, by2] + f_cols]\n",
    "\n",
    "    temp_df.loc[:, 'cluster_target'] = -1\n",
    "    temp_df.loc[:, 'cluster_level'] = -1\n",
    "\n",
    "    grouped_df = temp_df.groupby(by = by2, as_index = False)\n",
    "    grouped_df_count = grouped_df.count()\n",
    "    station_nm_list = list(grouped_df_count[grouped_df_count[by1] >= 2][by2])\n",
    "    target_range = np.arange(len(station_nm_list))\n",
    "\n",
    "    for i in target_range:\n",
    "        list_idx = temp_df.query('%s == \"%s\"' % (by2, station_nm_list[i])).index\n",
    "        for idx in list_idx:\n",
    "            temp_df.loc[idx, 'cluster_target'] = i\n",
    "            temp_df.loc[idx, 'cluster_level'] = n\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_result(df, n):\n",
    "    df.loc[:, 'cluster_level'] = n\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_dbscan_result(eps, station_df):\n",
    "    df_lv1_group = get_n_level_spatial_dbscan_result(station_df, 1, eps, min_pts = 3)\n",
    "    \n",
    "    df_lv2_group = df_lv1_group.query(target_s + ' == -1')\n",
    "    df_lv2_group = get_n_level_spatial_dbscan_result(df_lv2_group, 2, eps, min_pts = 2)\n",
    "    \n",
    "    df_noise_handled_group = df_lv2_group.query(target_s + ' == -1')\n",
    "    df_noise_handled_group = get_noise_handled_result(df_noise_handled_group, 3)\n",
    "    \n",
    "    df_noise_group = df_noise_handled_group.query(target_s + ' == -1')\n",
    "    df_noise_group = get_noise_result(df_noise_group, 4)\n",
    "    \n",
    "    r1 = df_lv1_group.query(target_s + ' > -1')\n",
    "    r2 = df_lv2_group.query(target_s + ' > -1')\n",
    "    r3 = df_noise_handled_group.query(target_s + ' > -1')\n",
    "    r4 = df_noise_group\n",
    "    \n",
    "    combined = pd.concat([r1, r2, r3, r4])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1 정류장 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Embedded\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "D:\\Users\\Embedded\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "eps_list = [110, 95]\n",
    "list_df_combined = []\n",
    "\n",
    "for i, station_df in enumerate(grouped_df_list):   \n",
    "    eps = eps_list[i]\n",
    "    # eps에 따른 dbscan 수행.\n",
    "    df_combined = get_spatial_dbscan_result(eps, station_df)\n",
    "    df_combined.loc[:, 'cluster_level'] = df_combined['cluster_level'].astype(str)\n",
    "    df_combined.loc[:, 'cluster_target'] = df_combined['cluster_target'].astype(str)\n",
    "    df_combined['level-target'] = df_combined['cluster_level'] + '&' + df_combined['cluster_target']\n",
    "\n",
    "    # lv별 grouping -> count -> 저장.\n",
    "    list_df_combined.append(df_combined)\n",
    "    \n",
    "for i in range(len(list_df_combined)):\n",
    "#     list_df_combined[i][\"cluster_group\"] = group_label_list[i]\n",
    "    list_df_combined[i] = list_df_combined[i][[\"station_id\", \"cluster_target\", \"cluster_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.concat(list_df_combined)\n",
    "df = pd.merge(df, cluster_df, on=\"station_id\", sort = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clustered_station_data\", encoding=\"CP949\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
