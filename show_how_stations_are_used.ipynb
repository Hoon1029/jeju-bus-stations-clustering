{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 상수\n",
    "user_id = 'user_id'\n",
    "base_date = 'base_date'\n",
    "route_id = 'route_id'\n",
    "route_name = 'route_name'\n",
    "route_no = 'route_no'\n",
    "geton_datetime = 'geton_datetime'\n",
    "geton_station_id = 'geton_station_id'\n",
    "geton_station_name = 'geton_stataion_name'\n",
    "geton_station_longitude = 'geton_station_longitude'\n",
    "geton_station_latitude = 'geton_station_latitude'\n",
    "getoff_datetime = 'getoff_datetime'\n",
    "getoff_station_id = 'getoff_station_id'\n",
    "getoff_station_name = 'getoff_station_name'\n",
    "getoff_station_longitude = 'getoff_station_longitude'\n",
    "getoff_station_latitude = 'getoff_station_latitude'\n",
    "user_type = 'user_type'\n",
    "user_count = 'user_count'\n",
    "input_date = 'input_date'\n",
    "usage = 'usage' # not excel column, for new DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(date):\n",
    "    root_path = \"C:/tb_bus_user_usage\"\n",
    "    base_name = \"tb_bus_user_usage_\"\n",
    "    extender = \".csv\"\n",
    "    \n",
    "    date = str(date)\n",
    "    y = date[2:4]\n",
    "    m = date[5:7]\n",
    "    d = date[8:10]\n",
    "    \n",
    "    file_name = root_path+\"/\"+base_name+y+m+d+extender\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_how_many_is_station_used(file_path):\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    df = pd.DataFrame(df[geton_station_name].value_counts())\n",
    "    df.index.name = geton_station_name\n",
    "    df = df.rename(columns={geton_station_name:usage})\n",
    "    return df\n",
    "\n",
    "def analyze_how_many_did_user_use_station(file_path):\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    df = df[[geton_station_name, user_count]].groupby(geton_station_name).sum()\n",
    "    df.index.name = geton_station_name\n",
    "    df = df.rename(columns={user_count:usage})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_result(df_a, df_b):\n",
    "    df_a_ = pd.DataFrame(index = set(df_b.index)-set(df_a.index))\n",
    "    df_b_ = pd.DataFrame(index = set(df_a.index)-set(df_b.index))\n",
    "\n",
    "    df_a_[usage] = 0\n",
    "    df_b_[usage] = 0\n",
    "    \n",
    "    df_a = pd.concat([df_a, df_a_])\n",
    "    df_b = pd.concat([df_b, df_b_])\n",
    "    \n",
    "#     df_a[usage].apply(lambda x:int(x))\n",
    "#     df_b[usage].apply(lambda x:int(x))\n",
    "    return df_a.add(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all(start_date, end_date, scale = \"station\"):# scale = [\"station\" | \"user\"]\n",
    "    if(scale == \"station\"):# select analyze function and scale column\n",
    "        scale = geton_station_name\n",
    "        analyze_func = analyze_how_many_is_station_used\n",
    "    elif(scale == \"user\"):\n",
    "        scale = user_count\n",
    "        analyze_func = analyze_how_many_did_user_use_station\n",
    "        \n",
    "    file_path = make_path(start_date)\n",
    "    result = pd.DataFrame(analyze_func(file_path))\n",
    "\n",
    "    for day in tqdm(range((end_date-start_date).days)):\n",
    "        date = start_date + datetime.timedelta(days = day+1)\n",
    "        print(date)\n",
    "        file_path = make_path(date)\n",
    "        result = combine_result(result, analyze_func(file_path))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             usage\n",
      "위미정수장            0\n",
      "굴집터              0\n",
      "이화농장             0\n",
      "이스트힐스            0\n",
      "이스트소프트           0\n",
      "...            ...\n",
      "동문로터리(동문시장)   2184\n",
      "제주시청(아라방면)    2430\n",
      "제주대학교         2670\n",
      "제주시청(광양방면)    2853\n",
      "한라병원          2859\n",
      "\n",
      "[1840 rows x 1 columns]\n",
      "             usage\n",
      "새소망요양병원          0\n",
      "선린지              0\n",
      "선인동사거리           0\n",
      "선흘1리운동장          0\n",
      "관광단지입구           0\n",
      "...            ...\n",
      "동문로터리(동문시장)   2240\n",
      "제주시청(아라방면)    2480\n",
      "제주대학교         2710\n",
      "제주시청(광양방면)    2911\n",
      "한라병원          2913\n",
      "\n",
      "[1840 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2019, 6, 1)\n",
    "end_date = datetime.datetime(2019, 6, 3)\n",
    "period = int((end_date-start_date).days)+1\n",
    "\n",
    "station_usage = analyze_all(start_date, end_date, scale = \"station\")\n",
    "station_user_usage = analyze_all(start_date, end_date, scale = \"user\")\n",
    "\n",
    "station_usage[usage] = station_usage[usage].apply(lambda x : int(x/period))\n",
    "station_user_usage[usage] = station_user_usage[usage].apply(lambda x : int(x/period))\n",
    "\n",
    "print(station_usage.sort_values(by = usage))\n",
    "print(station_user_usage.sort_values(by = usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[804, 766, 251, 19, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_value = [0, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "scale_column = usage\n",
    "result = []\n",
    "for i in range(6):\n",
    "    condition = str(scale_value[i])+\" <= \"+scale_column+\" and \" + scale_column +\" < \"+str(scale_value[i+1])\n",
    "    result.append(int(station_usage.query(condition).count()))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
