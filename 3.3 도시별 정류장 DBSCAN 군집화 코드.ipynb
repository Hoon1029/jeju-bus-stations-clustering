{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import bus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) grouping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group_column(df):\n",
    "    df['cluster_group'] = df['station_address'].apply(lambda string: string.split(' ')[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) clustering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_s = 'cluster_target'\n",
    "level_s = 'cluster_level'\n",
    "earth_radius = 6371.0088 # 단위: km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_level_spatial_dbscan_result \\\n",
    "    (df, n, eps, min_pts = 3, nonf_cols = ['station_id', 'station_name'], f_cols = ['station_x', 'station_y']):\n",
    "    global earth_radius \n",
    "    dbscan = DBSCAN(eps = eps/1000/earth_radius, algorithm='ball_tree', \n",
    "                    metric='haversine', min_samples=min_pts)\n",
    "    \n",
    "    temp_df = df.loc[:,nonf_cols + f_cols]\n",
    "    temp_df.loc[:, target_s] = dbscan.fit_predict(np.radians(temp_df[f_cols]))\n",
    "\n",
    "    success_index = temp_df.query(target_s + ' > -1').index\n",
    "    temp_df.loc[success_index, level_s] = str(n)\n",
    "    \n",
    "    failed_index = set(temp_df.index) - set(success_index)\n",
    "    temp_df.loc[failed_index, level_s] = str(-1)\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_handled_result \\\n",
    "    (df, n, by1='station_id', by2='station_name', f_cols=['station_x', 'station_y']):\n",
    "    temp_df = df.loc[:, [by1, by2] + f_cols]\n",
    "\n",
    "    temp_df['cluster_target'] = -1\n",
    "    temp_df['cluster_level'] = -1\n",
    "\n",
    "    grouped_df = temp_df.groupby(by = by2, as_index = False)\n",
    "    grouped_df_count = grouped_df.count()\n",
    "    station_nm_list = list(grouped_df_count[grouped_df_count[by1] >= 2][by2])\n",
    "    target_range = np.arange(len(station_nm_list))\n",
    "\n",
    "    for i in target_range:\n",
    "        list_idx = temp_df.query('%s == \"%s\"' % (by2, station_nm_list[i])).index\n",
    "        for idx in list_idx:\n",
    "            temp_df.loc[idx, 'cluster_target'] = i\n",
    "            temp_df.loc[idx, 'cluster_level'] = n\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_result(df, n):\n",
    "    df.loc[:, 'cluster_level'] = n\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_dbscan_result(eps, station_df):\n",
    "    df_lv1_group = get_n_level_spatial_dbscan_result(station_df, 1, eps, min_pts = 3)\n",
    "    \n",
    "    df_lv2_group = df_lv1_group.query(target_s + ' == -1')\n",
    "    df_lv2_group = get_n_level_spatial_dbscan_result(df_lv2_group, 2, eps, min_pts = 2)\n",
    "    \n",
    "    df_noise_handled_group = df_lv2_group.query(target_s + ' == -1')\n",
    "    df_noise_handled_group = get_noise_handled_result(df_noise_handled_group, 3)\n",
    "    \n",
    "    df_noise_group = df_noise_handled_group.query(target_s + ' == -1')\n",
    "    df_noise_group = get_noise_result(df_noise_group, 4)\n",
    "    \n",
    "    r1 = df_lv1_group.query(target_s + ' > -1')\n",
    "    r2 = df_lv2_group.query(target_s + ' > -1')\n",
    "    r3 = df_noise_handled_group.query(target_s + ' > -1')\n",
    "    r4 = df_noise_group\n",
    "    \n",
    "    combined = pd.concat([r1, r2, r3, r4])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Embedded\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "D:\\Users\\Embedded\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df = bus.create_station_df()\n",
    "\n",
    "df = make_group_column(df)\n",
    "\n",
    "group_list = set(df[\"cluster_group\"])\n",
    "group_df_list = []\n",
    "for label in group_list:\n",
    "    group_df_list.append(df[df[\"cluster_group\"] == label])\n",
    "\n",
    "    \n",
    "eps_list = [105, 90]\n",
    "# eps_list = [300, 200]\n",
    "cluster_df_list = []\n",
    "\n",
    "    \n",
    "for i, group_df in enumerate(group_df_list):   \n",
    "    eps = eps_list[i]\n",
    "    # eps에 따른 dbscan 수행. => label OR noise 생성\n",
    "    cluster_df = get_spatial_dbscan_result(eps, group_df)\n",
    "    cluster_df['cluster_level'] = cluster_df['cluster_level'].astype(str)\n",
    "    cluster_df['cluster_target'] = cluster_df['cluster_target'].astype(str)\n",
    "    cluster_df['level-target'] = cluster_df['cluster_level'] + '&' + cluster_df['cluster_target']\n",
    "    \n",
    "    # noise 군집에 개별 레이블 부여\n",
    "    cluster_df[\"cluster_target\"] = cluster_df[\"cluster_target\"].apply(lambda x : int(x))\n",
    "    next_target = int(max(list(cluster_df[\"cluster_target\"]))) + 1\n",
    "    for j in cluster_df.index:\n",
    "        if cluster_df.loc[j, \"cluster_target\"] == -1:\n",
    "            cluster_df.loc[j, \"cluster_target\"] = next_target\n",
    "            next_target += 1\n",
    "    \n",
    "    # 군집 위치 구하기\n",
    "    cluster_df[\"cluster_x\"] = 0\n",
    "    cluster_df[\"cluster_y\"] = 0\n",
    "    target_list = set(cluster_df[\"cluster_target\"])\n",
    "    for target in target_list:\n",
    "        target_df = cluster_df[cluster_df[\"cluster_target\"] == target]\n",
    "        cluster_x = target_df[\"station_x\"].mean()\n",
    "        cluster_y = target_df[\"station_y\"].mean()\n",
    "        cluster_df.loc[cluster_df[\"cluster_target\"] == target, \"cluster_x\"] = cluster_x\n",
    "        cluster_df.loc[cluster_df[\"cluster_target\"] == target, \"cluster_y\"] = cluster_y\n",
    "            \n",
    "    # 필수 컬럼만 추출\n",
    "    cluster_df = cluster_df[[\"station_id\", \"cluster_target\", \"cluster_level\", \"cluster_x\", \"cluster_y\"]]\n",
    "    cluster_df_list.append(cluster_df)\n",
    "\n",
    "# 그룹별 데이터를 하나로 묶음\n",
    "cluster_df = pd.concat(cluster_df_list)\n",
    "cluster_df = pd.merge(df, cluster_df, on=\"station_id\", sort = \"right\")\n",
    "cluster_df = cluster_df[[\"station_id\",\"cluster_group\", \"cluster_target\", \"cluster_level\", \"cluster_x\", \"cluster_y\"]]\n",
    "\n",
    "cluster_df.to_csv(\"cluster_list.csv\", encoding=\"CP949\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
