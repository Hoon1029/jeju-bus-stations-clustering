{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Do! 프로젝트 root 경로로 설정\n",
    "# project_path = \"D:/workspace/Bus Project\"\n",
    "project_path = \"/Users/jade/git/capstone/jeju-bus-tag_data-analysis\"\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import xml.etree.ElementTree as elemTree\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import bus.analyzer as anz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = anz.load_station_df()\n",
    "user_df = anz.load_user_df()\n",
    "cluster_df = anz.load_cluster_df()\n",
    "station_cluster_df = anz.load_cluster_station_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_df\n",
    "# user_df\n",
    "# cluster_df\n",
    "# station_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(func, df, core = multiprocessing.cpu_count()-4):\n",
    "    df_split = np.array_split(df, core)\n",
    "    pool = Pool(core)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_total_usage_data(input_path_list):\n",
    "    usage_df = pd.read_csv(input_path_list[0], low_memory=False, encoding = \"cp949\") #, dtype=dtype)\n",
    "    for file_path in tqdm(input_path_list[1:]):\n",
    "        temp_df = pd.read_csv(file_path, low_memory=False, encoding = \"cp949\") #, dtype=dtype)\n",
    "        usage_df = pd.concat([usage_df, temp_df], sort=False, ignore_index=True)\n",
    "        \n",
    "    usage_df = usage_df[usage_df[\"geton_station_longitude\"].notnull()]\n",
    "    usage_df = usage_df[usage_df[\"geton_station_latitude\"].notnull()]\n",
    "    \n",
    "    # datetime64로 형 변환 # M[base_date] = pd.to_datetime(M[base_date], format='%Y%m%d')\n",
    "    usage_df['geton_datetime'] = pd.to_datetime(usage_df['geton_datetime'], format='%Y%m%d%H%M%S')\n",
    "    usage_df['getoff_datetime'] = pd.to_datetime(usage_df['getoff_datetime'], format='%Y%m%d%H%M%S')\n",
    "    \n",
    "    return usage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기간 설정\n",
    "start_date = datetime.datetime(2019, 6, 1)\n",
    "end_date = datetime.datetime(2019, 8, 29)\n",
    "\n",
    "# 로딩할 파일 명 리스트 생성\n",
    "input_path_list = anz.make_input_path(start_date, end_date)\n",
    "\n",
    "station_usage_df = parallelize_dataframe(anz.load_total_usage_data, input_path_list, core = 10)\n",
    "\n",
    "user_df = anz.load_user_df()\n",
    "station_df = anz.load_station_df()\n",
    "cluster_df = anz.load_cluster_df()\n",
    "cluster_station_df = anz.load_cluster_station_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_usage_df(station_usage_df):\n",
    "    usage_selector = ['user_id', 'geton_datetime', 'geton_station_id', 'getoff_datetime', 'getoff_station_id']\n",
    "    station_usage_df = station_usage_df[usage_selector]\n",
    "\n",
    "    cluster_selector = cluster_station_df.columns\n",
    "\n",
    "    geton_columns = {}\n",
    "    getoff_columns = {}\n",
    "    for column in cluster_selector:\n",
    "        geton_columns[column] = \"geton_\"+column\n",
    "        getoff_columns[column] = \"getoff_\"+column\n",
    "        \n",
    "    geton_cluster_df = cluster_station_df.rename(columns=geton_columns)\n",
    "    getoff_cluster_df = cluster_station_df.rename(columns=getoff_columns)\n",
    "    \n",
    "    cluster_usage_df = pd.merge(station_usage_df, geton_cluster_df, on=['geton_station_id'], how=\"left\")\n",
    "    cluster_usage_df = pd.merge(cluster_usage_df, getoff_cluster_df, on=['getoff_station_id'], how=\"left\")\n",
    "    return cluster_usage_df\n",
    "\n",
    "cluster_usage_df = create_cluster_usage_df(station_usage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_usage(cluster_usage_df, user_df, tourist=True):\n",
    "    tourist_cluster_usage_selector = cluster_usage_df.columns\n",
    "    merged_df = pd.merge(cluster_usage_df, user_df, on=\"user_id\", how=\"left\")\n",
    "    tourist_cluster_usage_df = merged_df[merged_df[\"tourist\"] == tourist]\n",
    "    tourist_cluster_usage_df = tourist_cluster_usage_df[tourist_cluster_usage_selector]\n",
    "    return tourist_cluster_usage_df\n",
    "    \n",
    "cluster_usage_df = extract_usage(cluster_usage_df, user_df, tourist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_usage_grouped_user(cluster_usage_df):\n",
    "    user_list = cluster_usage_df[\"user_id\"].drop_duplicates()\n",
    "    usage_list = []\n",
    "    \n",
    "    for user_id in tqdm(user_list):\n",
    "        usage_list.append(cluster_usage_df[cluster_usage_df[\"user_id\"] == user_id])\n",
    "        \n",
    "    return usage_list\n",
    "\n",
    "usage_list = extract_usage_grouped_user(cluster_usage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, colony):\n",
    "        self.colony = colony\n",
    "        self.end_of_pattern = False\n",
    "        self.count = 0\n",
    "        # dictionary of next visited colonies\n",
    "        self.next = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie(object):\n",
    "    def __init__(self):\n",
    "        self.root = Node(-1)\n",
    "    \n",
    "    def insert(self, pattern):\n",
    "        node = self.root\n",
    "        \n",
    "        for colony in pattern:\n",
    "            #if colony exists in node's child, move to it\n",
    "            if colony in node.next:\n",
    "                node.count += 1\n",
    "                node = node.next[colony]\n",
    "            else:\n",
    "                # if colony is not found in child, create new node as child. \n",
    "                newNode = Node(colony)\n",
    "                node.next[colony] = newNode\n",
    "                node = newNode\n",
    "                node.count += 1\n",
    "                \n",
    "        node.end_of_pattern = True\n",
    "    \n",
    "    def dfs(self, node, pattern):\n",
    "        if node.end_of_pattern:\n",
    "            self.output.append(pattern)\n",
    "            return \n",
    "        \n",
    "        for next_node in node.next.values():\n",
    "            pattern.append(next_node.colony)\n",
    "            self.dfs(next_node, pattern)\n",
    "            pattern = []\n",
    "    \n",
    "    def query(self, cluster_x):\n",
    "        self.output = []\n",
    "        node = self.root\n",
    "        \n",
    "        if cluster_x in node.next:\n",
    "            pattern = []\n",
    "            self.dfs(node.next[cluster_x], pattern)\n",
    "            \n",
    "        return self.output\n",
    "    \n",
    "    def dfs_n(self, node, pattern, n, i):\n",
    "        if not i:\n",
    "            self.output.append(pattern)\n",
    "            i = n\n",
    "            return\n",
    "        \n",
    "        for next_node in node.next.values():\n",
    "            pattern.append(next_node.colony)\n",
    "            i -= 1\n",
    "            self.dfs(next_node, pattern, n, i)\n",
    "            pattern = []\n",
    "    \n",
    "    def query_upto_n_clusters(self, cluster_x, n):\n",
    "        self.output = []\n",
    "        node = self.root\n",
    "            \n",
    "        if cluster_x in node.next:\n",
    "            pattern = []\n",
    "            self.dfs_n(node.next[cluster_x], pattern, n, n)\n",
    "            \n",
    "        return self.output    \n",
    "\n",
    "    def dfs_p(self, node, pattern):\n",
    "        if node.end_of_pattern:\n",
    "            self.output.append(pattern)\n",
    "            return\n",
    "        \n",
    "        max_col1 = max(node.next.items(), key=lambda x:x[1].count)[0]\n",
    "        max_cnt_list = [k for k, v in node.next.items() if node.next[max_col1].count == v.count]\n",
    "        \n",
    "        for max_node in max_cnt_list:\n",
    "            pattern.append(node.next[max_node].colony)\n",
    "            self.dfs_p(node.next[max_node], pattern)\n",
    "            pattern = []\n",
    "    \n",
    "    def query_by_popularity(self, cluster_x):\n",
    "        self.output = []\n",
    "        node = self.root\n",
    "        \n",
    "        if cluster_x in node.next:\n",
    "            pattern = []\n",
    "            self.dfs_p(node.next[cluster_x], pattern)\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern_validity(prev_getoff_time, cur_geton_time):\n",
    "    return True\n",
    "    \n",
    "def get_patterns(user, pattern_candidates):\n",
    "    patterns = [[]]\n",
    "    p_idx = 0\n",
    "    \n",
    "    for pattern in pattern_candidates:\n",
    "        for idx in pattern:\n",
    "            patterns[p_idx].append(user['geton_cluster_id'][idx])\n",
    "            patterns[p_idx].append(user['getoff_cluster_id'][idx])\n",
    "        p_idx += 1\n",
    "    \n",
    "    return patterns \n",
    "        \n",
    "            \n",
    "def get_all_pattern_candidates(user):\n",
    "    pattern_candidates = [[]]\n",
    "    p_idx = 0 # pattern candidates idx in patterns\n",
    "    prev_getoff_time = user.iloc[0]['getoff_datetime']\n",
    "    \n",
    "    for data in user.index:\n",
    "        cur_geton_time = user['geton_datetime'][data]\n",
    "        \n",
    "        if check_pattern_validity(prev_getoff_time, cur_geton_time):\n",
    "            pattern_candidates[p_idx].append(data)\n",
    "        else:\n",
    "            p_idx += 1\n",
    "            pattern_candidates[p_idx].append(data)\n",
    "            \n",
    "        prev_getoff_time = user['getoff_datetime'][data] \n",
    "    \n",
    "    return pattern_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_patterns(patterns):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_trie = Trie()\n",
    "\n",
    "for user in usage_list:\n",
    "    # patterns by index\n",
    "    pattern_candidates = get_all_pattern_candidates(user)\n",
    "    # patterns by cluster_id\n",
    "    patterns = get_patterns(user, pattern_candidates)\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        pattern_trie.insert(pattern)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
